@book{ross2022simulation,
  title={Simulation},
  author={Ross, S.M.},
  isbn={9780323899611},
  url={https://books.google.co.in/books?id=z8JrEAAAQBAJ},
  year={2022},
  publisher={Elsevier Science}
}

@book{dasgupta2011probability,
  title={Probability for statistics and machine learning: fundamentals and advanced topics},
  author={DasGupta, Anirban},
  year={2011},
  publisher={Springer}
}

@book{gamerman2006markov,
  title={Markov Chain Monte Carlo: Stochastic Simulation for Bayesian Inference, Second Edition},
  author={Gamerman, D. and Lopes, H.F.},
  isbn={9781482296426},
  series={Chapman \& Hall/CRC Texts in Statistical Science},
  url={https://books.google.co.in/books?id=X01ZDwAAQBAJ},
  year={2006},
  publisher={CRC Press}
}

@book{wasserman_all_2013,
	title = {All of {Statistics}: {A} {Concise} {Course} in {Statistical} {Inference}},
	isbn = {978-0-387-21736-9},
	shorttitle = {All of {Statistics}},
	abstract = {Taken literally, the title "All of Statistics" is an exaggeration. But in spirit, the title is apt, as the book does cover a much broader range of topics than a typical introductory book on mathematical statistics. This book is for people who want to learn probability and statistics quickly. It is suitable for graduate or advanced undergraduate students in computer science, mathematics, statistics, and related disciplines. The book includes modern topics like nonparametric curve estimation, bootstrapping, and clas sification, topics that are usually relegated to follow-up courses. The reader is presumed to know calculus and a little linear algebra. No previous knowledge of probability and statistics is required. Statistics, data mining, and machine learning are all concerned with collecting and analyzing data. For some time, statistics research was con ducted in statistics departments while data mining and machine learning re search was conducted in computer science departments. Statisticians thought that computer scientists were reinventing the wheel. Computer scientists thought that statistical theory didn't apply to their problems. Things are changing. Statisticians now recognize that computer scientists are making novel contributions while computer scientists now recognize the generality of statistical theory and methodology. Clever data mining algo rithms are more scalable than statisticians ever thought possible. Formal sta tistical theory is more pervasive than computer scientists had realized.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Wasserman, Larry},
	month = dec,
	year = {2013},
	note = {Google-Books-ID: qrcuBAAAQBAJ},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Counting \& Numeration, Mathematics / Discrete Mathematics, Mathematics / Numerical Analysis, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes, Science / Physics / General},
}

@article{geweke_evaluating_1995,
	title = {Evaluating the {Accuracy} of {Sampling}-{Based} {Approaches} to the {Calculation} of {Posterior} {Moments}},
	volume = {4},
	abstract = {Data augmentation and Gibbs sampling are two closely related, sampling-based approaches to the calculation of posterior moments. The fact that each produces a sample whose constituents are neither independent nor identically distributed complicates the assessment of convergence and numerical accuracy of the approximations to the expected value of functions of interest under the posterior. In this paper methods from spectral analysis are used to evaluate numerical accuracy formally and construct diagnostics for convergence. These methods are illustrated in the normal linear model with informative priors, and in the Tobit-censored regression model. Keywords and phrases: Data augmentation, Gibbs sampling, Mixed estimation, Monte Carlo integration, Tobit model This paper was prepared as an invited presentation at the Fourth Valencia International Meeting on Bayesian Statistics, Peiscola, Spain, April 15-20, 1991. Financial support from National Science Foundation Grant SES-8908365 and re...},
	author = {Geweke, John and In, Forthcoming},
	month = nov,
	year = {1995},
}

@article{hastings_monte_1970,
	title = {Monte {Carlo} {Sampling} {Methods} {Using} {Markov} {Chains} and {Their} {Applications}},
	volume = {57},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2334940},
	doi = {10.2307/2334940},
	abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
	number = {1},
	urldate = {2024-03-07},
	journal = {Biometrika},
	author = {Hastings, W. K.},
	year = {1970},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {97--109},
	file = {JSTOR Full Text PDF:/home/azmain/Zotero/storage/IXV7KVXZ/Hastings - 1970 - Monte Carlo Sampling Methods Using Markov Chains a.pdf:application/pdf},
}

@article{ross2014first,
    title={A first course in probability},
    author={Ross, Sheldon M},
    year={2014},
    publisher={Pearson Boston}
}

@book{blitzstein_introduction_2019,
	address = {New York},
	edition = {2},
	title = {Introduction to {Probability}, {Second} {Edition}},
	isbn = {978-0-429-42835-7},
	abstract = {Developed from celebrated Harvard statistics lectures, Introduction to Probability provides essential language and tools for understanding statistics, randomness, and uncertainty. The book explores a wide variety of applications and examples, ranging from coincidences and paradoxes to Google PageRank and Markov chain Monte Carlo (MCMC). Additional application areas explored include genetics, medicine, computer science, and information theory.　 
The authors present the material in an accessible style and motivate concepts using real-world examples. Throughout, they use stories to uncover connections between the fundamental distributions in statistics and conditioning to reduce complicated problems to manageable pieces.The book includes many intuitive explanations, diagrams, and practice problems. Each chapter ends with a section showing how to perform relevant simulations and calculations in R, a free statistical software environment.
The second edition adds many new examples, exercises, and explanations, to deepen understanding of the ideas, clarify subtle concepts, and respond to feedback from many students and readers. New supplementary online resources have been developed, including animations and interactive visualizations, and the book has been updated to dovetail with these resources.　
Supplementary material is available on Joseph Blitzstein’s website www. stat110.net. The supplements include:Solutions to selected exercisesAdditional practice problemsHandouts including review material and sample exams Animations and interactive visualizations created in connection with the edX online version of Stat 110.Links to lecture videos available on ITunes U and YouTube There is also a complete instructor's solutions manual available to instructors who require the book for a course.},
	publisher = {Chapman and Hall/CRC},
	author = {Blitzstein, Joseph K. and Hwang, Jessica},
	month = feb,
	year = {2019},
	doi = {10.1201/9780429428357},
}
